{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oV7AzzOpj8x"
      },
      "source": [
        "# 基于 VGG-11 的 FashionMNIST 数据集的分类\n",
        "## 1. 导入 FashionMNIST 数据集\n",
        "首先我们下载 FashionMNIST， 这需要定义一个导入函数 load_FashionMNIST_dataset 和类别标签函数 get_FashionMNIST_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_6bCz4cpj80"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import functional\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter(\"runs/FashionMNIST/VGG\")\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "ROOT = './data'\n",
        "\n",
        "def load_FashionMNIST_dataset(BatchSize, root=ROOT):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.Normalize(0.5, 0.5)\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.FashionMNIST(root, train=True, transform=transform, download=True)\n",
        "    trainloader = data.DataLoader(trainset,batch_size=BatchSize,shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.FashionMNIST(root, train=False, transform=transform, download=True)\n",
        "    testloader = data.DataLoader(testset,batch_size=BatchSize,shuffle=False,num_workers=2)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat','sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7szmpza0pj81"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img/2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg,(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "2B5l1rhupj82",
        "outputId": "9e162191-b806-4c84-98a6-6ab03e842ed7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4275f7f16cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# img_grid = torchvision.utils.make_grid(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(img_grid.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-fbcc8ef9af3c>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: axes don't match array"
          ]
        }
      ],
      "source": [
        "BatchSize = 128\n",
        "trains,tests = load_FashionMNIST_dataset(BatchSize)\n",
        "\n",
        "trainiter = iter(trains)\n",
        "X, y = next(trainiter)\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(X)\n",
        "print(img_grid.shape)\n",
        "imshow(img_grid)\n",
        "print([labels[idx] for idx in y])\n",
        "\n",
        "# writer.add_images(\"Some Samples\",X)\n",
        "# writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyENI9d7pj83"
      },
      "source": [
        "## 2. VGG\n",
        "### 基本架构\n",
        "VGG 的输入输出与全连接层与 AlexNet基本相同，不同的是 VGG 引入 5 个卷积块，实现了块状设计。其基本架构分为两部分：第一部分主要由卷积层和汇聚层组成的卷积块，第二部分由全连接层组成。\n",
        "\n",
        "\n",
        "输入：图片（$3\\times 224\\times 224$）\n",
        "\n",
        "模块一（卷积块1-2）：\n",
        "- $3\\times 3$ 卷积（64），填充为 1 (64 @ 224*224)\n",
        "- ReLU 函数激活\n",
        "- $2\\times 2$ 最大汇聚，步幅为 2 （64 @ 112*112）\n",
        "- $3\\times 3$ 卷积（128），填充为 1 （128 @ 112*112）\n",
        "- ReLU 函数激活\n",
        "- $2\\times 2$ 最大汇聚，步幅为 2 （128 @ 56*56）\n",
        "\n",
        "模块二（卷积块3-5）：\n",
        "- $3\\times 3$ 卷积（256），填充为 1 （256 @ 56*56）\n",
        "- ReLU 函数激活\n",
        "- $3\\times 3$ 卷积（256），填充为 1 （256 @ 56*56）\n",
        "- ReLU 函数激活\n",
        "- $2\\times 2$ 最大汇聚，步幅为 2 （256 @ 28*28）\n",
        "- $3\\times 3$ 卷积（512），填充为 1 （512 @ 28*28）\n",
        "- ReLU 函数激活\n",
        "- $3\\times 3$ 卷积（512），填充为 1 （512 @ 28*28）\n",
        "- ReLU 函数激活\n",
        "- $2\\times 2$ 最大汇聚，步幅为 2 （512 @ 14*14）\n",
        "- $3\\times 3$ 卷积（512），填充为 1 （512 @ 14*14）\n",
        "- ReLU 函数激活\n",
        "- $3\\times 3$ 卷积（512），填充为 1 （512 @ 14*14）\n",
        "- ReLU 函数激活\n",
        "- $2\\times 2$ 最大汇聚，步幅为 2 （512 @ 7*7）\n",
        "- Flatten 展平\n",
        "- 全连接层（512\\*7*7，4096）\n",
        "- ReLU 函数激活\n",
        "- Dropout(0.5)\n",
        "- 全连接层（4096，4096）\n",
        "- ReLU 函数激活\n",
        "- Dropout(0.5)\n",
        "- 全连接层（4096，1000）\n",
        "- softmax 函数分类输出\n",
        "\n",
        "输出：1000 个类别样本\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKCWtEmspj84"
      },
      "outputs": [],
      "source": [
        "def vgg_block(num_convs, in_chanels, out_chanels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.Conv2d(in_chanels, out_chanels,\n",
        "        kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "        in_chanels = out_chanels\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "conv_archs = ((1,64), (1,128), (2,256), (2,512), (2,512))\n",
        "\n",
        "def VGG11(conv_archs):\n",
        "    conv_blks = []\n",
        "    in_chanel = 1\n",
        "    for (num_convs, out_chanel) in conv_archs:\n",
        "        conv_blks.append(vgg_block(num_convs, in_chanel, out_chanel))\n",
        "        in_chanel = out_chanel\n",
        "\n",
        "    return nn.Sequential(\n",
        "        *conv_blks, \n",
        "        nn.Flatten(), \n",
        "        nn.Linear(512*7*7,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,10))\n",
        "\n",
        "vgg11 = VGG11(conv_archs)\n",
        "# writer.add_graph(vgg11,X)\n",
        "# writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24zjJvJKpj85",
        "outputId": "230f6269-af9f-4116-da34-2545afb5b264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on!\n",
            "Finish Training\n"
          ]
        }
      ],
      "source": [
        "def train(epochs,net, criterion, opt, train_set,device):\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            \n",
        "    net.apply(init_weights)\n",
        "    print(\"Training on!\")\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        net.train()\n",
        "        for i, (X,y) in enumerate(train_set,0):\n",
        "            opt.zero_grad()\n",
        "            X,y = X.to(device), y.to(device)\n",
        "            pred = net(X)\n",
        "            loss = criterion(pred, y)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        if i % 100 ==99:\n",
        "            print(f\"epoch {epoch}, i = {i}: loss={running_loss/100}\")\n",
        "            running_loss = 0\n",
        "    print(\"Finish Training\")\n",
        "    return net.eval()\n",
        "\n",
        "epochs = 2\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg11.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "net = train(epochs,vgg11,criterion,optimizer,trains,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPqDA0c6pj85",
        "outputId": "ae638ba3-e13d-43c4-b0a8-fd03e8bac3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of train sets: 0.1\n",
            "Accuracy of test sets: 0.1\n"
          ]
        }
      ],
      "source": [
        "def accuracy(net, datasets, device):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for _,(X,y) in enumerate(datasets,0):\n",
        "            X,y = X.to(device),y.to(device)\n",
        "            outputs = net(X)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (preds==y).sum().item()\n",
        "    return correct/total\n",
        "\n",
        "print(\"Accuracy of train sets:\", accuracy(net, trains,device))\n",
        "print(\"Accuracy of test sets:\", accuracy(net, tests, device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUeeS1-4pj86"
      },
      "outputs": [],
      "source": [
        "def pred_to_probs(net, X):\n",
        "    output = net(X)\n",
        "    _,preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.numpy())\n",
        "    return preds, [torch.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "def plot_class_preds(net, X, y):\n",
        "    preds, probs = pred_to_probs(net, X)\n",
        "    fig = plt.figure(figsize=(12,48))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1,4, idx+1, xticks=[], yticks=[])\n",
        "        img_grid = torchvision.utils.make_grid(X[idx])\n",
        "        imshow(img_grid)\n",
        "        ax.set_title(\"{0},{1:.1f}%\\n(label: {2})\".format(\n",
        "            labels[preds[idx]],\n",
        "            probs[idx]*100,\n",
        "            labels[y[idx]]),\n",
        "            color = (\"green\" if preds[idx] == y[idx].item() else \"red\"))\n",
        "    return fig\n",
        "\n",
        "testiter = iter(tests)\n",
        "X, y = next(testiter)\n",
        "net.cpu()\n",
        "plot_class_preds(net,X, y)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}